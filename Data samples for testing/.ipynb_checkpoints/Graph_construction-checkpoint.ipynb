{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMRSMZSXzhtC",
    "outputId": "ebd5bb22-f026-4dd6-94c4-f463e889e1cf"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-5-bf2eb2fac634>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-bf2eb2fac634>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pyspark --conf “spark.ui.port=10101”\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "#pyspark --conf “spark.ui.port=10101”\n",
    "\n",
    "!pip install pyspark\n",
    "!pip install -U -q PyDrive\n",
    "!apt install openjdk-8-jdk-headless -qq\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tR-2I83UziZs"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7f0ea5eddfa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2FCUVaE9zrdt"
   },
   "outputs": [],
   "source": [
    "# Let's import the libraries we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H2DjQMZYz9bm"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d06d5231beb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# create the Spark Session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sc.stop()\n",
    "\n",
    "# create the Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# create the Spark Context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWsb0hHlBR5Q"
   },
   "source": [
    "# DATA\n",
    "### Upload the data and remove header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "UMNZDXo90Wef"
   },
   "outputs": [],
   "source": [
    "filename = \"small_sample_data.csv\"\n",
    "#filename = \"transaction_data.csv\"\n",
    "\n",
    "lines = sc.textFile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "1VNrhGmm2rvV"
   },
   "outputs": [],
   "source": [
    "header = lines.first()\n",
    "lines = lines.filter(lambda line: line != header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxJugdycDSjC"
   },
   "source": [
    "# FILE with all pairs with normalized weights `(PRODUCT PAIRS ---> WEIGHTS)`\n",
    "\n",
    "\n",
    "> `product_pairs_normalized.txt`: one line represents one tuple `(prod1_ID, prod2_ID, normalized_weight)` (situation (C) on Figure 3 in original paper).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atwyoQJJ78uT"
   },
   "source": [
    "### Helper functions\n",
    "for data frame updates over lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "PpZaqJHu77a1"
   },
   "outputs": [],
   "source": [
    "def make_list(line):\n",
    "  \"\"\"\n",
    "    Input: one line of df of format as in original data\n",
    "    Output: a pair (basket_ID, product_ID)\n",
    "  \"\"\"\n",
    "  splitted = line.split()\n",
    "\n",
    "  lst = splitted[0].split(\",\")\n",
    "  lst = list(map(lambda x: x, lst))\n",
    "\n",
    "  BASKET_ID = int(lst[1])\n",
    "  PRODUCT_ID = int(lst[3])\n",
    "  QUANTITY = int(lst[4])\n",
    "  #return BASKET_ID, (PRODUCT_ID, QUANTITY)\n",
    "  return BASKET_ID, PRODUCT_ID\n",
    "\n",
    "\n",
    "# Use this function only if quantity of products in baskests need to be taken into account. \n",
    "# In this case, use the other return statement in function \"make_list\" first\n",
    "def make_multiple_products(line):\n",
    "  BASKET_ID = line[0]\n",
    "  PRODUCT_ID = line[1][0]\n",
    "  QUANTITY = line[1][1]\n",
    "\n",
    "  new_lst = (BASKET_ID, QUANTITY * [PRODUCT_ID])\n",
    "\n",
    "  return new_lst\n",
    "\n",
    "\n",
    "def generate_pairs_of_elements(line):\n",
    "  \"\"\"\n",
    "    Input: one line of format: (basket_id, (prod1_id, prod2_id, ... prodn_id))\n",
    "    Output: pairs between all products with assigned weight, self-loops get weight 0: ((prod1_id, prod1_id, 0), (prod1_id, prod2_id, 1), ..., (prod1_id, prodn_id, 1), (prod2_id, prod1_id, 1), (prod2_id, prod2_id, 0), ...)\n",
    "  \"\"\"\n",
    "  BASKET_ID = line[0]\n",
    "  PRODUCTS_IDS = line[1]\n",
    "\n",
    "  pairs = []\n",
    "\n",
    "  if len(PRODUCTS_IDS) == 1:\n",
    "    pairs.append(((PRODUCTS_IDS[0], PRODUCTS_IDS[0]), 0))\n",
    "    return pairs\n",
    "\n",
    "  else:\n",
    "    for ID1 in PRODUCTS_IDS:\n",
    "      pairs.append(((ID1, ID1), 0))\n",
    "      for ID2 in PRODUCTS_IDS:\n",
    "        if ID1 != ID2:\n",
    "          pairs.append(((ID1, ID2), 1))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "LSIL4EN71hY8"
   },
   "outputs": [],
   "source": [
    "basket_list = lines.map(make_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "xfUmUAkK7AIp"
   },
   "outputs": [],
   "source": [
    "baskets_content = basket_list.groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "h8piaFxiAZFD"
   },
   "outputs": [],
   "source": [
    "generated_pairs = baskets_content.flatMap(generate_pairs_of_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "ExLasf6MAisP"
   },
   "outputs": [],
   "source": [
    "unique_pairs = generated_pairs.groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "MJV4rXKOBPBl"
   },
   "outputs": [],
   "source": [
    "sum_unique_pairs = unique_pairs.map(lambda pair: (pair[0], np.sum(pair[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "u5ZF8ksTO2_U"
   },
   "outputs": [],
   "source": [
    "sum_unique_pairs_correction = sum_unique_pairs.map(lambda pair: (pair[0], 1 if pair[1] == 0 else pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "o8UKpYTePpIR"
   },
   "outputs": [],
   "source": [
    "W = sum_unique_pairs_correction.map(lambda line: line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "ggVhEFe7U1BK"
   },
   "outputs": [],
   "source": [
    "# ČASOVNO POTRATNO !!!!\n",
    "norm = W.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "mKfWk1REQJQc"
   },
   "outputs": [],
   "source": [
    "normalized_unique_pairs = sum_unique_pairs_correction.map(lambda pair: (pair[0], pair[1] / norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "chtG1tY9RdUv"
   },
   "outputs": [],
   "source": [
    "#normalized_unique_pairs.saveAsTextFile(\"product_pairs_normalized.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZUvVyj9IviG"
   },
   "source": [
    "# FILE with content of every basket `(BASKET --- time stamp ---> PRODUCTS)`\n",
    "\n",
    "\n",
    "> `baskets_content.txt`: lines formatted as `(Basket_ID, (time_stamp), [pairs between all products from that basket])`, bottom situation on Figure 3 in original paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XalbEiNOLL4"
   },
   "source": [
    "### Helper functions\n",
    "for data frame updates over lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "_UVE00ZIARvO"
   },
   "outputs": [],
   "source": [
    "def make_line_basket_product(line):\n",
    "  \"\"\"\n",
    "    Input: one line of df of format as in original data\n",
    "    Output: (basket_ID, (week_no, day, trans_time)), product_ID\n",
    "  \"\"\"\n",
    "  splitted = line.split()\n",
    "\n",
    "  lst = splitted[0].split(\",\")\n",
    "  lst = list(map(lambda x: x, lst))\n",
    "\n",
    "  HOUSEHOLD_KEY = int(lst[0])\n",
    "\n",
    "  WEEK_NO = int(lst[9])\n",
    "  DAY = int(lst[2])\n",
    "  TRANS_TIME = int(lst[8])\n",
    "\n",
    "  BASKET_ID = int(lst[1])\n",
    "  PRODUCT_ID = int(lst[3])\n",
    "\n",
    "  return (BASKET_ID, (WEEK_NO, DAY, TRANS_TIME)), PRODUCT_ID\n",
    "\n",
    "\n",
    "\n",
    "def KEY_generate_pairs_of_elements(line):\n",
    "  \"\"\"\n",
    "    Input: one line of format: (basket_ID, (week_no, day, trans_time)), product\n",
    "    Output: key + pairs between all products with assigned weight, self-loops get weight 0: ((prod1_id, prod1_id, 0), (prod1_id, prod2_id, 1), ..., (prod1_id, prodn_id, 1), (prod2_id, prod1_id, 1), (prod2_id, prod2_id, 0), ...)\n",
    "  \"\"\"\n",
    "  KEY = line[0]\n",
    "  print(KEY)\n",
    "  PRODUCTS_IDS = line[1]\n",
    "  print(PRODUCTS_IDS)\n",
    "\n",
    "  pairs = []\n",
    "\n",
    "  if len(PRODUCTS_IDS) == 1:\n",
    "    pairs.append((PRODUCTS_IDS[0], PRODUCTS_IDS[0]))\n",
    "    return KEY, pairs\n",
    "\n",
    "  else:\n",
    "    for ID1 in PRODUCTS_IDS:\n",
    "      pairs.append((ID1, ID1))\n",
    "      for ID2 in PRODUCTS_IDS:\n",
    "        if ID1 != ID2:\n",
    "          pairs.append((ID1, ID2))\n",
    "\n",
    "  return KEY, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "2ZMNLS5yBKwP"
   },
   "outputs": [],
   "source": [
    "house_time_products_line = lines.map(make_line_basket_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "msNGdsE8BR5M"
   },
   "outputs": [],
   "source": [
    "grouped_basket = house_time_products_line.groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "OvD_NLcNCSGB"
   },
   "outputs": [],
   "source": [
    "grouped_pairs = grouped_basket.map(KEY_generate_pairs_of_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "FyZJCfB0C9qj"
   },
   "outputs": [],
   "source": [
    "#grouped_pairs.saveAsTextFile(\"basket_content.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvXaBBGNOqCe"
   },
   "source": [
    "# FILE with baskets of household `(HOUSEHOLD ---> BASKETS)`\n",
    "\n",
    "\n",
    "> `household_basket.txt`: lines formatted as `(HOUSEHOLD_KEY, [all BASKET_IDs])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7FKZw_GPJJc"
   },
   "source": [
    "### Helper functions\n",
    "for data frame updates over lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "pk2y39aYDNqn"
   },
   "outputs": [],
   "source": [
    "def make_line_household_basket(line):\n",
    "  \"\"\"\n",
    "    Input: one line of df of format as in original data\n",
    "    Output: household_key, basket_id\n",
    "  \"\"\"\n",
    "  splitted = line.split()\n",
    "\n",
    "  lst = splitted[0].split(\",\")\n",
    "  lst = list(map(lambda x: x, lst))\n",
    "\n",
    "  HOUSEHOLD_KEY = int(lst[0])\n",
    "  BASKET_ID = int(lst[1])\n",
    "\n",
    "  WEEK_NO = int(lst[9])\n",
    "  DAY = int(lst[2])\n",
    "  TRANS_TIME = int(lst[8])\n",
    "\n",
    "  return HOUSEHOLD_KEY, (BASKET_ID, (WEEK_NO, DAY, TRANS_TIME))\n",
    "\n",
    "def make_unique_list_of_vals(line):\n",
    "  key = line[0]\n",
    "  vals_list = line[1]\n",
    "  unique_list = list(set(vals_list))\n",
    "  return key, sorted(unique_list, key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "id": "IWEJcGtXPU8O"
   },
   "outputs": [],
   "source": [
    "house_basket_line = lines.map(make_line_household_basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "id": "e6xksix1PgtB"
   },
   "outputs": [],
   "source": [
    "grouped_by_house = house_basket_line.groupByKey().mapValues(list)\n",
    "grouped_by_house_unique = grouped_by_house.map(make_unique_list_of_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "kVeH7O5yQYGo"
   },
   "outputs": [],
   "source": [
    "#grouped_by_house_unique.saveAsTextFile(\"household_basket.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTp4pe_twK-j"
   },
   "source": [
    "--------\n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "id": "dlY4xx5WwLrf"
   },
   "outputs": [],
   "source": [
    "# ČASOVNO POTRATNO !!!\n",
    "LIST1 = normalized_unique_pairs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "id": "g1a_9XrRwPxQ"
   },
   "outputs": [],
   "source": [
    "  dct1 = {}\n",
    "  for element in LIST1:\n",
    "    pair = element[0]\n",
    "    weight = element[1]\n",
    "    dct1[pair] = (pair, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "wBJAGApc7uTC"
   },
   "outputs": [],
   "source": [
    "def change_pairs(dictionary):\n",
    "  def change_pairs_(line):\n",
    "    new_lst = [dictionary[pair] for pair in line[1]]\n",
    "    return line[0], new_lst\n",
    "  return change_pairs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "id": "iVyVNN6amEYv"
   },
   "outputs": [],
   "source": [
    "# JOIN NORMALIZED_UNIQUE_PAIRS and GROUPED_PAIRS ! \n",
    "basket_normalized_pairs = grouped_pairs.map(change_pairs(dct1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "556eGiuU_jrz",
    "outputId": "c76cbc18-2158-4fab-daca-055040146a32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1364, [(26984896261, (1, 1, 1520))])]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_by_house_unique.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "id": "kBHju0wWwUPP"
   },
   "outputs": [],
   "source": [
    "# ČASOVNO POTRATNO !!!\n",
    "LIST2 = basket_normalized_pairs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "id": "JRIUB-iH_Uip"
   },
   "outputs": [],
   "source": [
    "  dct2 = {}\n",
    "  for element in LIST2:\n",
    "    basket = element[0]\n",
    "    pairs = element[1]\n",
    "    dct2[basket] = (basket, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "id": "d87L_wvqJCSl"
   },
   "outputs": [],
   "source": [
    "def join_all(dictionary):\n",
    "  def join_all_(line):\n",
    "    new_lst = [dictionary[basket] for basket in line[1]]\n",
    "    return line[0], new_lst\n",
    "  return join_all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "id": "D_l_ZUvtJWD7"
   },
   "outputs": [],
   "source": [
    "# JOIN ALL\n",
    "joined = grouped_by_house_unique.map(join_all(dct2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "id": "DWe6zqhRbeMA"
   },
   "outputs": [],
   "source": [
    "def make_prod_list(line):\n",
    "  prod_list = []\n",
    "  house_ID = line[0]\n",
    "  baskets_number = len(line[1])\n",
    "  for i in range(baskets_number):\n",
    "    products_number = len(line[1][i][1])\n",
    "    for j in range(products_number):\n",
    "      prod1, prod2 = line[1][i][1][j][0]\n",
    "      prod_list.append(prod1)\n",
    "      prod_list.append(prod2)\n",
    "  return house_ID, list(set(prod_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "7WzyUc4WJe7H"
   },
   "outputs": [],
   "source": [
    "# (HOUSE, [products for house])\n",
    "products_for_house = joined.map(make_prod_list).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "FM8IPF3Nch9V"
   },
   "outputs": [],
   "source": [
    "prod_for_house = {}\n",
    "for element in products_for_house:\n",
    "  prod_for_house[element[0]] = element[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwGjq6LYiIjg",
    "outputId": "d386cf57-caba-41b9-a9c0-c793c9724b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prod_for_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "id": "-ztzLMf3KNv3"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from google.colab import files\n",
    "\n",
    "def make_graphs(prod_for_house):\n",
    "  def make_graphs_(line):\n",
    "    house_ID = line[0]\n",
    "    # Teli nodi bodo v vseh grafih\n",
    "    nodes = prod_for_house[house_ID]\n",
    "    baskets_number = len(line[1])\n",
    "\n",
    "    graphs = []\n",
    "\n",
    "    # Za vsako košarko svoj graf\n",
    "    for i in range(baskets_number):\n",
    "      G = nx.Graph()\n",
    "      G.add_nodes_from(nodes)\n",
    "      basket_ID = line[1][i][0]\n",
    "      products_number = len(line[1][i][1])\n",
    "\n",
    "      for j in range(products_number):\n",
    "        n1, n2 = line[1][i][1][j][0]\n",
    "        W = line[1][i][1][j][1]\n",
    "        G.add_edge(n1, n2, weight = W)\n",
    "\n",
    "      # Zapišemo in shranimo graf\n",
    "      graphs.append(G)\n",
    "      #nx.write_pajek(G, f\"{house_ID}_{i}.net\")\n",
    "      #files.download(f\"{house_ID}_{i}.net\")\n",
    "\n",
    "    return house_ID, graphs\n",
    "  return make_graphs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "id": "4McXfTwhJsPL"
   },
   "outputs": [],
   "source": [
    "GRAPHS_RDD = joined.map(make_graphs(prod_for_house))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHMJ7PI5Fwgd",
    "outputId": "a4c8effd-37e6-4656-bb15-af4bdb1ba07b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1364, [<networkx.classes.graph.Graph at 0x7fa8b6ca9cd0>]),\n",
       " (1130, [<networkx.classes.graph.Graph at 0x7fa8bfb54090>]),\n",
       " (98, [<networkx.classes.graph.Graph at 0x7fa8bf932ad0>]),\n",
       " (1172, [<networkx.classes.graph.Graph at 0x7fa8bfb542d0>]),\n",
       " (1060, [<networkx.classes.graph.Graph at 0x7fa8bf932050>]),\n",
       " (2375,\n",
       "  [<networkx.classes.graph.Graph at 0x7fa8bfb36150>,\n",
       "   <networkx.classes.graph.Graph at 0x7fa8bf904c50>]),\n",
       " (1173, [<networkx.classes.graph.Graph at 0x7fa8bfb36650>])]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRAPHS_RDD.take(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "id": "xhVqBOgigJnD"
   },
   "outputs": [],
   "source": [
    "GRAPHS = GRAPHS_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mT3k2Imqfi5",
    "outputId": "b2358eda-99e3-45bd-f82d-6789128d08d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/1364_0.net': No such file or directory\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/1130_0.net': No such file or directory\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/98_0.net': No such file or directory\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/1172_0.net': No such file or directory\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/1060_0.net': No such file or directory\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/2375_0.net': No such file or directory\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/2375_1.net': No such file or directory\n",
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "touch: cannot touch 'f/content/gdrive/My Drive/Graphs/1173_0.net': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")\n",
    "\n",
    "for element in GRAPHS:\n",
    "  house_ID = element[0]\n",
    "  list_of_graphs = element[1]\n",
    "  for i, G in enumerate(list_of_graphs):\n",
    "    nx.write_pajek(G, f\"{house_ID}_{i}.net\")\n",
    "    #files.download(f\"{house_ID}_{i}.net\")\n",
    "    #drive.mount(\"/content/gdrive\")\n",
    "    #!touch f\"/content/gdrive/My Drive/Graphs/{house_ID}_{i}.net\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "id": "V9yHkE-z6G2T"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3upuCW5-pRL",
    "outputId": "e2311eea-dbc7-4bd0-dde5-e2a7d1d0f491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "tgGGFKnu-sIG"
   },
   "outputs": [],
   "source": [
    "!touch \"/content/gdrive/My Drive/Graphs/1060_0.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFMbF7D0_QeP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ElementRelationshipLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

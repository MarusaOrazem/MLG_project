{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ElementRelationshipLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMRSMZSXzhtC",
        "outputId": "469967ed-9410-4bac-f406-f4c0167249af"
      },
      "source": [
        "# pyspark --conf “spark.ui.port=10101”\n",
        "\n",
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 41 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 45.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=a9d26e2fa5fa69e5487f0c6b2edb56908b80f6592a3ee81abd5cee8a291d9e5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR-2I83UziZs"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FCUVaE9zrdt"
      },
      "source": [
        "# Let's import the libraries we will need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2DjQMZYz9bm"
      },
      "source": [
        "sc = SparkContext.getOrCreate()\n",
        "sc.stop()\n",
        "\n",
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWsb0hHlBR5Q"
      },
      "source": [
        "# DATA\n",
        "### Upload the data and remove header"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMNZDXo90Wef"
      },
      "source": [
        "filename = \"small_sample_data.csv\"\n",
        "#filename = \"transaction_data.csv\"\n",
        "\n",
        "lines = sc.textFile(filename)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VNrhGmm2rvV"
      },
      "source": [
        "header = lines.first()\n",
        "lines = lines.filter(lambda line: line != header)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxJugdycDSjC"
      },
      "source": [
        "# FILE with all pairs with normalized weights `(PRODUCT PAIRS ---> WEIGHTS)`\n",
        "\n",
        "\n",
        "> `product_pairs_normalized.txt`: one line represents one tuple `(prod1_ID, prod2_ID, normalized_weight)` (situation (C) on Figure 3 in original paper).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atwyoQJJ78uT"
      },
      "source": [
        "### Helper functions\n",
        "for data frame updates over lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpZaqJHu77a1"
      },
      "source": [
        "def make_list(line):\n",
        "  \"\"\"\n",
        "    Input: one line of df of format as in original data\n",
        "    Output: a pair (basket_ID, product_ID)\n",
        "  \"\"\"\n",
        "  splitted = line.split()\n",
        "\n",
        "  lst = splitted[0].split(\",\")\n",
        "  lst = list(map(lambda x: x, lst))\n",
        "\n",
        "  BASKET_ID = int(lst[1])\n",
        "  PRODUCT_ID = int(lst[3])\n",
        "  QUANTITY = int(lst[4])\n",
        "  #return BASKET_ID, (PRODUCT_ID, QUANTITY)\n",
        "  return BASKET_ID, PRODUCT_ID\n",
        "\n",
        "\n",
        "# Use this function only if quantity of products in baskests need to be taken into account. \n",
        "# In this case, use the other return statement in function \"make_list\" first\n",
        "def make_multiple_products(line):\n",
        "  BASKET_ID = line[0]\n",
        "  PRODUCT_ID = line[1][0]\n",
        "  QUANTITY = line[1][1]\n",
        "\n",
        "  new_lst = (BASKET_ID, QUANTITY * [PRODUCT_ID])\n",
        "\n",
        "  return new_lst\n",
        "\n",
        "\n",
        "def generate_pairs_of_elements(line):\n",
        "  \"\"\"\n",
        "    Input: one line of format: (basket_id, (prod1_id, prod2_id, ... prodn_id))\n",
        "    Output: pairs between all products with assigned weight, self-loops get weight 0: ((prod1_id, prod1_id, 0), (prod1_id, prod2_id, 1), ..., (prod1_id, prodn_id, 1), (prod2_id, prod1_id, 1), (prod2_id, prod2_id, 0), ...)\n",
        "  \"\"\"\n",
        "  BASKET_ID = line[0]\n",
        "  PRODUCTS_IDS = line[1]\n",
        "\n",
        "  pairs = []\n",
        "\n",
        "  if len(PRODUCTS_IDS) == 1:\n",
        "    pairs.append(((PRODUCTS_IDS[0], PRODUCTS_IDS[0]), 0))\n",
        "    return pairs\n",
        "\n",
        "  else:\n",
        "    for ID1 in PRODUCTS_IDS:\n",
        "      pairs.append(((ID1, ID1), 0))\n",
        "      for ID2 in PRODUCTS_IDS:\n",
        "        if ID1 != ID2:\n",
        "          pairs.append(((ID1, ID2), 1))\n",
        "\n",
        "    return pairs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSIL4EN71hY8"
      },
      "source": [
        "basket_list = lines.map(make_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfUmUAkK7AIp"
      },
      "source": [
        "baskets_content = basket_list.groupByKey().mapValues(list)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8piaFxiAZFD"
      },
      "source": [
        "generated_pairs = baskets_content.flatMap(generate_pairs_of_elements)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExLasf6MAisP"
      },
      "source": [
        "unique_pairs = generated_pairs.groupByKey().mapValues(list)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJV4rXKOBPBl"
      },
      "source": [
        "sum_unique_pairs = unique_pairs.map(lambda pair: (pair[0], np.sum(pair[1])))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5ZF8ksTO2_U"
      },
      "source": [
        "sum_unique_pairs_correction = sum_unique_pairs.map(lambda pair: (pair[0], 1 if pair[1] == 0 else pair[1]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8UKpYTePpIR"
      },
      "source": [
        "W = sum_unique_pairs_correction.map(lambda line: line[1])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggVhEFe7U1BK"
      },
      "source": [
        "norm = W.max()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKfWk1REQJQc"
      },
      "source": [
        "normalized_unique_pairs = sum_unique_pairs_correction.map(lambda pair: (pair[0], pair[1] / norm))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chtG1tY9RdUv"
      },
      "source": [
        "#normalized_unique_pairs.saveAsTextFile(\"product_pairs_normalized.txt\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZUvVyj9IviG"
      },
      "source": [
        "# FILE with content of every basket `(BASKET --- time stamp ---> PRODUCTS)`\n",
        "\n",
        "\n",
        "> `baskets_content.txt`: lines formatted as `(Basket_ID, (time_stamp), [pairs between all products from that basket])`, bottom situation on Figure 3 in original paper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XalbEiNOLL4"
      },
      "source": [
        "### Helper functions\n",
        "for data frame updates over lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UVE00ZIARvO"
      },
      "source": [
        "def make_line_basket_product(line):\n",
        "  \"\"\"\n",
        "    Input: one line of df of format as in original data\n",
        "    Output: (basket_ID, (week_no, day, trans_time)), product_ID\n",
        "  \"\"\"\n",
        "  splitted = line.split()\n",
        "\n",
        "  lst = splitted[0].split(\",\")\n",
        "  lst = list(map(lambda x: x, lst))\n",
        "\n",
        "  HOUSEHOLD_KEY = int(lst[0])\n",
        "\n",
        "  WEEK_NO = int(lst[9])\n",
        "  DAY = int(lst[2])\n",
        "  TRANS_TIME = int(lst[8])\n",
        "\n",
        "  BASKET_ID = int(lst[1])\n",
        "  PRODUCT_ID = int(lst[3])\n",
        "\n",
        "  return (BASKET_ID, (WEEK_NO, DAY, TRANS_TIME)), PRODUCT_ID\n",
        "\n",
        "\n",
        "\n",
        "def KEY_generate_pairs_of_elements(line):\n",
        "  \"\"\"\n",
        "    Input: one line of format: (basket_ID, (week_no, day, trans_time)), product\n",
        "    Output: key + pairs between all products with assigned weight, self-loops get weight 0: ((prod1_id, prod1_id, 0), (prod1_id, prod2_id, 1), ..., (prod1_id, prodn_id, 1), (prod2_id, prod1_id, 1), (prod2_id, prod2_id, 0), ...)\n",
        "  \"\"\"\n",
        "  KEY = line[0]\n",
        "  print(KEY)\n",
        "  PRODUCTS_IDS = line[1]\n",
        "  print(PRODUCTS_IDS)\n",
        "\n",
        "  pairs = []\n",
        "\n",
        "  if len(PRODUCTS_IDS) == 1:\n",
        "    pairs.append((PRODUCTS_IDS[0], PRODUCTS_IDS[0]))\n",
        "    return KEY, pairs\n",
        "\n",
        "  else:\n",
        "    for ID1 in PRODUCTS_IDS:\n",
        "      pairs.append((ID1, ID1))\n",
        "      for ID2 in PRODUCTS_IDS:\n",
        "        if ID1 != ID2:\n",
        "          pairs.append((ID1, ID2))\n",
        "\n",
        "  return KEY, pairs\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZMNLS5yBKwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb19936d-0145-4caf-b694-cf937b20d0e4"
      },
      "source": [
        "house_time_products_line = lines.map(make_line_basket_product)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((26984851472, (1, 1, 1631)), 1004906),\n",
              " ((26984851472, (1, 1, 1631)), 1033142),\n",
              " ((26984851472, (1, 1, 1631)), 1036325),\n",
              " ((26984851472, (1, 1, 1631)), 1082185),\n",
              " ((26984851472, (1, 1, 1631)), 8160430)]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msNGdsE8BR5M"
      },
      "source": [
        "grouped_basket = house_time_products_line.groupByKey().mapValues(list)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvD_NLcNCSGB"
      },
      "source": [
        "grouped_pairs = grouped_basket.map(KEY_generate_pairs_of_elements)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyZJCfB0C9qj"
      },
      "source": [
        "#grouped_pairs.saveAsTextFile(\"basket_content.txt\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvXaBBGNOqCe"
      },
      "source": [
        "# FILE with baskets of household `(HOUSEHOLD ---> BASKETS)`\n",
        "\n",
        "\n",
        "> `household_basket.txt`: lines formatted as `(HOUSEHOLD_KEY, [all BASKET_IDs])`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7FKZw_GPJJc"
      },
      "source": [
        "### Helper functions\n",
        "for data frame updates over lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk2y39aYDNqn"
      },
      "source": [
        "def make_line_household_basket(line):\n",
        "  \"\"\"\n",
        "    Input: one line of df of format as in original data\n",
        "    Output: household_key, basket_id\n",
        "  \"\"\"\n",
        "  splitted = line.split()\n",
        "\n",
        "  lst = splitted[0].split(\",\")\n",
        "  lst = list(map(lambda x: x, lst))\n",
        "\n",
        "  HOUSEHOLD_KEY = int(lst[0])\n",
        "  BASKET_ID = int(lst[1])\n",
        "\n",
        "  WEEK_NO = int(lst[9])\n",
        "  DAY = int(lst[2])\n",
        "  TRANS_TIME = int(lst[8])\n",
        "\n",
        "  return HOUSEHOLD_KEY, (BASKET_ID, (WEEK_NO, DAY, TRANS_TIME))\n",
        "\n",
        "def make_unique_list_of_vals(line):\n",
        "  key = line[0]\n",
        "  vals_list = line[1]\n",
        "  return key, list(set(vals_list))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWEJcGtXPU8O"
      },
      "source": [
        "house_basket_line = lines.map(make_line_household_basket)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6xksix1PgtB"
      },
      "source": [
        "grouped_by_house = house_basket_line.groupByKey().mapValues(list)\n",
        "grouped_by_house_unique = grouped_by_house.map(make_unique_list_of_vals)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVeH7O5yQYGo"
      },
      "source": [
        "#grouped_by_house_unique.saveAsTextFile(\"household_basket.txt\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTp4pe_twK-j"
      },
      "source": [
        "--------\n",
        "-----\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlY4xx5WwLrf"
      },
      "source": [
        "LIST1 = normalized_unique_pairs.collect()"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1a_9XrRwPxQ"
      },
      "source": [
        "  dct1 = {}\n",
        "  for element in LIST1:\n",
        "    pair = element[0]\n",
        "    weight = element[1]\n",
        "    dct1[pair] = (pair, weight)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBJAGApc7uTC"
      },
      "source": [
        "def change_pairs(dictionary):\n",
        "  def change_pairs_(line):\n",
        "    new_lst = [dictionary[pair] for pair in line[1]]\n",
        "    return line[0], new_lst\n",
        "  return change_pairs_"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVyVNN6amEYv"
      },
      "source": [
        "# JOIN NORMALIZED_UNIQUE_PAIRS and GROUPED_PAIRS ! \n",
        "basket_normalized_pairs = grouped_pairs.map(change_pairs(dct1))"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "556eGiuU_jrz",
        "outputId": "26eb1859-9159-4ab1-caee-f90afa8c9724"
      },
      "source": [
        "grouped_by_house_unique.take(1)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1364, [(26984896261, (1, 1, 1520))])]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBHju0wWwUPP"
      },
      "source": [
        "LIST2 = basket_normalized_pairs.collect()"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRIUB-iH_Uip"
      },
      "source": [
        "  dct2 = {}\n",
        "  for element in LIST2:\n",
        "    basket = element[0]\n",
        "    pairs = element[1]\n",
        "    dct2[basket] = (basket, pairs)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d87L_wvqJCSl"
      },
      "source": [
        "def join_all(dictionary):\n",
        "  def join_all_(line):\n",
        "    new_lst = [dictionary[basket] for basket in line[1]]\n",
        "    return line[0], new_lst\n",
        "  return join_all_"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_l_ZUvtJWD7"
      },
      "source": [
        "# JOIN ALL\n",
        "joined = grouped_by_house_unique.map(join_all(dct2))"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WzyUc4WJe7H"
      },
      "source": [
        "#joined.saveAsTextFile(\"JOINED.txt\")"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjBYt0iyJj3S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
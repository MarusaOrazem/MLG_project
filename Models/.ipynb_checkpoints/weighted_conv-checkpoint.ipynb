{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WEIGHTED CONVOLUTION ON DYNAMIC GRAPHS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to construct a convolutions on dynamic graphs. \n",
    "Input for this module is a sequence of dynamic graphs $\\mathbb{G}_i = \\{\\mathcal{G}_i^1,...\\mathcal{G}_i^T\\}$, where graph $\\mathcal{G}_i^t \\in \\mathbb{G}_i$ has a sequene of elements represented as $\\{e_{i,j}^t \\in \\mathbb{R}^F, \\forall v_{i,j} \\in \\mathcal{V}_i\\}$. (F is the dimention of element representation equal to `in_features` and *i* is the considered household)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each graph $\\mathcal{G}_i$ the output of this modelue is a new sequence representation, which we will denote as  $\\{c_{i,j}^t \\in \\mathbb{R}^{F'}, \\forall v_{i,j} \\in \\mathcal{V}_i\\}$. (F' is the new dimension equal to `out_features`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the parameter scale and also make our method flexible to deal with sequences with variable lengths, a parameter sharing strategy is adopted. The weighted convolutions are implemented by propagating information of elements in each dynamic graphs as follows. For graph $\\mathcal{G}_i$\n",
    "$$c_{i,j}^{t,l+1} = \\sigma\\left( b^l + \\sum_{k \\in N_{i,j}^t \\cup \\{j\\}}   A_i^t[j,k] \\cdot \\left( W^t c_{i,k}^{t,l} \\right) \\right),$$ where $A_i^t[j,k]$ represents the item in j-th row and k-th column of matrix $A_i^t$, which is the edge weight of $v_{i,j}$ and $v_{i,k}$ in graph $\\mathcal{G}_i^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to override the `nn.Module` for constructing our convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional layer**\n",
    "For the convolutions, we're going to use the `GCNConv` layer from the PyG library. The convolutions are realized as follows:\n",
    "\n",
    "$$\\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "\\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta}$$, where $\\mathbf{\\hat{A}} = \\mathbf{A + I}$ is the adjacency matrix of a graph with inserted self-loops, and $\\mathbf{\\hat{D}}$ is its diagonal degree matrix.\n",
    "\n",
    "PyG makes the use of convolutions simple by simpy asking us to input the node feature tensor of shape `[num_of_nodes, num_of_features]` and its Sparse transposed adjecency matrix `adj_t`, which takes into account the weights in our graphs.\n",
    "\n",
    "Here are some other terms needed to understand the following code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.ModuleList()` - Holds submodules in a list. <br>\n",
    "`nn.ReLU()` - Applies the rectified linear unit function element-wise: ReLU(x) = max(0,x) <br>\n",
    "`nn.BatchNorm1d` - Applies Batch Normalization over a 2D or 3D input. $y=\\frac{x-E[x]}{\\sqrt{var[x]+\\epsilon}} \\cdot \\gamma + \\beta$, The mean and standard-deviation are calculated per-dimension over the mini-batches and \\gammaγ and \\betaβ are learnable parameter vectors of size C (where C is the input size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weighted_GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_sizes, out_features):\n",
    "        '''\n",
    "        :param in_features: int, number of input features\n",
    "        :param hidden_sizes: List[int], list of integers of hidden sizes\n",
    "        :param out_features: int, number of output features\n",
    "        '''\n",
    "        super(weighted_GCN, self).__init__()\n",
    "        # we are going to use 3 layers, first graph conv we wrote before, ReLu function and normalization\n",
    "        gcns, relus, bns = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()\n",
    "        \n",
    "        # layers for hidden_sizeŽ\n",
    "        input_size = in_features\n",
    "        for hidden_size in hidden_sizes:\n",
    "            # go through all the layers and call all three functions\n",
    "            gcns.append(GCNConv(in_channels=input_size, \n",
    "                            out_channels=hidden_size,\n",
    "                            improved=False,\n",
    "                            cached=False,\n",
    "                            add_self_loops=False,\n",
    "                            normalize=False,\n",
    "                            bias=False)) \n",
    "            relus.append(nn.ReLU())\n",
    "            bns.append(nn.BatchNorm1d(hidden_size))\n",
    "            input_size = hidden_size # next layer start size will be output from one layer before\n",
    "        \n",
    "        # output layer\n",
    "        gcns.append(GCNConv(in_channels=hidden_sizes[-1], \n",
    "                            out_channels=out_features,\n",
    "                            improved=False,\n",
    "                            cached=False,\n",
    "                            add_self_loops=False,\n",
    "                            normalize=False,\n",
    "                            bias=False\n",
    "                            )\n",
    "                   )\n",
    "        relus.append(nn.ReLU())\n",
    "        bns.append(nn.BatchNorm1d(out_features))\n",
    "        self.gcns, self.relus, self.bns = gcns, relus, bns\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        \"\"\"\n",
    "        :param graph: dgl.DGLGraph\n",
    "        :param node_features: torch.Tensor shape (n_1+n_2+..., n_features)\n",
    "               edges_weight: torch.Tensor shape (T, n_1^2+n_2^2+...)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        for gcn, relu, bn in zip(self.gcns, self.relus, self.bns):\n",
    "            \n",
    "            #run the Convolutional layer\n",
    "            h = gcn(h, adj_t)\n",
    "            #run the batch norm\n",
    "            h = bn(h.transpose(1, -1)).transpose(1, -1)\n",
    "            #run the ReLu\n",
    "            h = relu(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3464/179004681.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m## we construct a NX graph and cast it to pytorch.data.Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pajek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/Test-Graphs/content/Graphs/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_networkx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\MLG-Project\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36margmap_read_pajek_1\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_random_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_py_random_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\MLG-Project\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dispatch_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0margmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_arg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_finally\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
    "import torch_geometric.transforms as T\n",
    "import torch_sparse\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "#Here we specify our final network dimensions ##TODO: Make this prettier\n",
    "\n",
    "embedding_dim = 5  ## F'\n",
    "hidden_dims = [256, 256]\n",
    "\n",
    "shopping_per_hh = {}\n",
    "\n",
    "#This is just a test -- we're only constructing the graphs for houshold id 22 as a proof of concept!\n",
    "for filename in os.listdir(\"../data/Test-Graphs/content/Graphs/\"):\n",
    "    splits = filename.split('_')\n",
    "    hh_id = splits[0]\n",
    "    if hh_id not in shopping_per_hh: shopping_per_hh[hh_id] = []\n",
    "    \n",
    "    \n",
    "    ## we construct a NX graph and cast it to pytorch.data.Data\n",
    "    G = nx.Graph(nx.read_pajek(os.path.join(\"../data/Test-Graphs/content/Graphs/\",filename)))\n",
    "    data = from_networkx(G)\n",
    "\n",
    "    ## Then, we override the data.x in data to get the desired format of the dimensions.\n",
    "    ## We're just using a vector of ones here. We can chamge this in the long run to get more expressivness.\n",
    "    x = torch.ones(G.number_of_nodes(), 1)\n",
    "    data.x = x\n",
    "    \n",
    "    shopping_per_hh[hh_id].append(data)\n",
    "\n",
    "## We initialize a model\n",
    "\n",
    "final_tensors = {}\n",
    "for hh in shopping_per_hh.keys():\n",
    "    \n",
    "    in_dims = shopping_per_hh[hh][0].num_features\n",
    "    model = weighted_GCN(in_dims, \n",
    "                         hidden_dims, \n",
    "                         embedding_dim)\n",
    "\n",
    "    embeddings_at_t = []\n",
    "    ## iterate over all graphs for a givn household\n",
    "    for i in range(len(shopping_per_hh[hh])):\n",
    "        graph = shopping_per_hh[hh][i]\n",
    "        o = model(graph.x,graph.edge_index)\n",
    "        embeddings_at_t.append(o)\n",
    "        \n",
    "    ## initialize a dictionary of lists for each item purchased by this household at a shop\n",
    "    item_embeddings = {j : [] for j in range(len(embeddings_at_t[0]))}\n",
    "    for t in range(len(embeddings_at_t)):\n",
    "        for j in range(len(embeddings_at_t[t])):\n",
    "            ## and add the embeddings for each item to its corresponding temporal index t in the newly created list\n",
    "            item_embeddings[j].append(embeddings_at_t[t][j].tolist())\n",
    "    \n",
    "    ## convert the final 3D array to a tensor and save it to the dictionary for further use.\n",
    "    final_tensors[hh] = torch.tensor(list(lib.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[109, 1], edge_index=[2, 1], y=[109], id=[109], shape=[109], weight=[1])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here is an attempt of me constructing a PyG dataset. It's not working as intended atm. \n",
    "## TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "class ShoppingDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return  os.listdir(\"../data/Test-Graphs/content/Graphs/\")\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'not_implemented.pt'\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for i, dat in enumerate(data_list):\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{i}.pt'))\n",
    "#         for raw_path in self.raw_paths:\n",
    "#             # Read data from `raw_path`.\n",
    "#             data = Data(...)\n",
    "\n",
    "#             if self.pre_filter is not None and not self.pre_filter(data):\n",
    "#                 continue\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data = self.pre_transform(data)\n",
    "\n",
    "#             torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "#             idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data\n",
    "\n",
    "ds = ShoppingDataset(root='../data/ShoppingDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: This still isn't used.\n",
    "## This class was used before for prepping our representations for the attention based temporal learning modulee. It's not used anywhere at the moment.\n",
    "class stacked_weighted_GCN_blocks(nn.ModuleList):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(stacked_weighted_GCN_blocks, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        nodes_feature, edge_weights = input\n",
    "        h = nodes_feature\n",
    "        for module in self:\n",
    "            h = module(h, edge_weights)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLG-Project",
   "language": "python",
   "name": "mlg-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

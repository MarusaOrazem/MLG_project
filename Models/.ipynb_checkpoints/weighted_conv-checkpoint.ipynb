{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WEIGHTED CONVOLUTION ON DYNAMIC GRAPHS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to construct a convolutions on dynamic graphs. \n",
    "Input for this module is a sequence of dynamic graphs $\\mathbb{G}_i = \\{\\mathcal{G}_i^1,...\\mathcal{G}_i^T\\}$, where graph $\\mathcal{G}_i^t \\in \\mathbb{G}_i$ has a sequene of elements represented as $\\{e_{i,j}^t \\in \\mathbb{R}^F, \\forall v_{i,j} \\in \\mathcal{V}_i\\}$. (F is the dimention of element representation equal to `in_features` and *i* is the considered household)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each graph $\\mathcal{G}_i$ the output of this modelue is a new sequence representation, which we will denote as  $\\{c_{i,j}^t \\in \\mathbb{R}^{F'}, \\forall v_{i,j} \\in \\mathcal{V}_i\\}$. (F' is the new dimension equal to `out_features`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the parameter scale and also make our method flexible to deal with sequences with variable lengths, a parameter sharing strategy is adopted. The weighted convolutions are implemented by propagating information of elements in each dynamic graphs as follows. For graph $\\mathcal{G}_i$\n",
    "$$c_{i,j}^{t,l+1} = \\sigma\\left( b^l + \\sum_{k \\in N_{i,j}^t \\cup \\{j\\}}   A_i^t[j,k] \\cdot \\left( W^t c_{i,k}^{t,l} \\right) \\right),$$ where $A_i^t[j,k]$ represents the item in j-th row and k-th column of matrix $A_i^t$, which is the edge weight of $v_{i,j}$ and $v_{i,k}$ in graph $\\mathcal{G}_i^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to override the `nn.Module` for constructing our convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional layer**\n",
    "For the convolutions, we're going to use the `GCNConv` layer from the PyG library. The convolutions are realized as follows:\n",
    "\n",
    "$$\\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "\\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta}$$, where $\\mathbf{\\hat{A}} = \\mathbf{A + I}$ is the adjacency matrix of a graph with inserted self-loops, and $\\mathbf{\\hat{D}}$ is its diagonal degree matrix.\n",
    "\n",
    "PyG makes the use of convolutions simple by simpy asking us to input the node feature tensor of shape `[num_of_nodes, num_of_features]` and its Sparse transposed adjecency matrix `adj_t`, which takes into account the weights in our graphs.\n",
    "\n",
    "Here are some other terms needed to understand the following code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.ModuleList()` - Holds submodules in a list. <br>\n",
    "`nn.ReLU()` - Applies the rectified linear unit function element-wise: ReLU(x) = max(0,x) <br>\n",
    "`nn.BatchNorm1d` - Applies Batch Normalization over a 2D or 3D input. $y=\\frac{x-E[x]}{\\sqrt{var[x]+\\epsilon}} \\cdot \\gamma + \\beta$, The mean and standard-deviation are calculated per-dimension over the mini-batches and \\gammaγ and \\betaβ are learnable parameter vectors of size C (where C is the input size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weighted_GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_sizes, out_features):\n",
    "        '''\n",
    "        :param in_features: int, number of input features\n",
    "        :param hidden_sizes: List[int], list of integers of hidden sizes\n",
    "        :param out_features: int, number of output features\n",
    "        '''\n",
    "        super(weighted_GCN, self).__init__()\n",
    "        # we are going to use 3 layers, first graph conv we wrote before, ReLu function and normalization\n",
    "        gcns, relus, bns = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()\n",
    "        \n",
    "        # layers for hidden_size\n",
    "        input_size = in_features\n",
    "        for hidden_size in hidden_sizes:\n",
    "            # go through all the layers and call all three functions\n",
    "            gcns.append(GCNConv(input_size, hidden_size)) \n",
    "            relus.append(nn.ReLU())\n",
    "            bns.append(nn.BatchNorm1d(hidden_size))\n",
    "            input_size = hidden_size # next layer start size will be output from one layer before\n",
    "        \n",
    "        # output layer\n",
    "        gcns.append(GCNConv(hidden_sizes[-1], out_features))\n",
    "        relus.append(nn.ReLU())\n",
    "        bns.append(nn.BatchNorm1d(out_features))\n",
    "        self.gcns, self.relus, self.bns = gcns, relus, bns\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        \"\"\"\n",
    "        :param graph: dgl.DGLGraph\n",
    "        :param node_features: torch.Tensor shape (n_1+n_2+..., n_features)\n",
    "               edges_weight: torch.Tensor shape (T, n_1^2+n_2^2+...)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        # calculate\n",
    "        i = 0 #this is here to check if how many iterations we're running. Comment out if not needed\n",
    "        for gcn, relu, bn in zip(self.gcns, self.relus, self.bns):\n",
    "            \n",
    "            print(f'iteration {i}')\n",
    "            #run the Convolutional layer\n",
    "            h = gcn(h, adj_t)\n",
    "            #run the batch norm\n",
    "            h = bn(h.transpose(1, -1)).transpose(1, -1)\n",
    "            #run the ReLu\n",
    "            h = relu(h)\n",
    "            i += 1\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to represents this embeddings as a matrix $C_{i,j} \\in \\mathbb{R}^{T \\times F'}$, where each row $t$ represents $c_{i,j}^t$. <br>\n",
    "\n",
    "`class stacked_weighted_GCN_blocks` will construct such matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TODO: This still isn't used.\n",
    "class stacked_weighted_GCN_blocks(nn.ModuleList):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(stacked_weighted_GCN_blocks, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        nodes_feature, edge_weights = input\n",
    "        h = nodes_feature\n",
    "        for module in self:\n",
    "            h = module(h, edge_weights)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[109, 2], edge_index=[2, 841], y=[109], id=[109], shape=[109], weight=[841])\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
    "import torch_geometric.transforms as T\n",
    "import torch_sparse\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "\n",
    "#Here we specify our final network dimensions ##TODO: Make this prettier\n",
    "embedding_dim = 2\n",
    "hidden_dims = [256, 256]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "#This is just a test -- we're only constructing the graphs for houshold id 22 as a proof of concept!\n",
    "for filename in os.listdir(\"../data/Test-Graphs/content/Graphs/\"):\n",
    "    if filename[:3] != \"22_\": continue\n",
    "    \n",
    "    \n",
    "    ## we construct a NX graph and cast it to pytorch.data.Data\n",
    "    G = nx.Graph(nx.read_pajek(os.path.join(\"../data/Test-Graphs/content/Graphs/\",filename)))\n",
    "    data = from_networkx(G, group_node_attrs=None)\n",
    "    \n",
    "    ## Then, we override the data.x in data to get the desired format of the dimensions.\n",
    "    ## Here, we're inputting two custom features -- the degree and pagerank centrality of nodes.\n",
    "    ## In the long term, we're probably just going to go with a tensor of zeros here.\n",
    "    x = torch.tensor([list(dict(G.degree()).values()),\n",
    "list(dict(nx.algorithms.link_analysis.pagerank_alg.pagerank(G)).values())]).t()\n",
    "    data.x = x\n",
    "    data_list.append(data)\n",
    "\n",
    "## We initialize a model\n",
    "model = weighted_GCN(data_list[0].num_features, hidden_dims, embedding_dim)\n",
    "\n",
    "\n",
    "## Here we look at how our data instance looks and try to run one instance through the model.\n",
    "print(data_list[0])\n",
    "o = model(data_list[0].x, torch_sparse.SparseTensor(row=data_list[0].edge_index[0], col=data_list[0].edge_index[1], value=data_list[0].weight).t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an attempt of me constructing a PyG dataset. It's not working as intended atm. \n",
    "## TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-64fde12ee454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacked_weighted_GCN_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mblocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\MLG-Project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e41396261c62>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "class ShoppingDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return  os.listdir(\"../data/Test-Graphs/content/Graphs/\")\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'not_implemented.pt'\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for i, dat in enumerate(data_list):\n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{i}.pt'))\n",
    "#         for raw_path in self.raw_paths:\n",
    "#             # Read data from `raw_path`.\n",
    "#             data = Data(...)\n",
    "\n",
    "#             if self.pre_filter is not None and not self.pre_filter(data):\n",
    "#                 continue\n",
    "\n",
    "#             if self.pre_transform is not None:\n",
    "#                 data = self.pre_transform(data)\n",
    "\n",
    "#             torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "#             idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data\n",
    "\n",
    "ds = ShoppingDataset(root='../data/ShoppingDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLG-Project] *",
   "language": "python",
   "name": "conda-env-MLG-Project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

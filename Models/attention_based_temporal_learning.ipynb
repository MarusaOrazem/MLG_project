{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION ASED TEMPORAL DEPENDENCY LEARNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to learn temporal dependency among products bought and as we know from everyday life, some elements (products) will appear in our basket quite frequently and regularly, while others will appear irregularly and occasionally. This makes the temporal dependency learning really hard! <br>\n",
    "Previous models, such as RNNs, fail to model this kind of data,  because they do not take into account the temporal dependency learning. We are going to construct our model, using self attention, so that we will not loose this information, we are going to construct a temporal dependeny learning component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input** to this component will be the sequences we have construccted in the previous step (weighted GCN), where the output were the sequences of embeddings $\\mathbb{C}_i = \\{C_{i,1},...,C_{i,|\\mathcal{V}_i|}\\} $ where $C_{i,j}=\\{c_{i,j}^1,...,c_{i,j}^T\\}$, are the representations of $v_{i,j}$ over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **output** of this component will be $\\mathbb{Z}_i = \\{z_{i,1},...,z_{i,|\\mathcal{V}_i|}\\}$, where $z_{i,j} \\in \\mathbb{R}^{F''} $ are the representations of $v_{i,j} \\in \\mathcal{V}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_{i,j} \\in \\mathbb{R}^{T \\times F'}\n",
    "\\xrightarrow[\\text{}]{\\text{temporal dependency}}\n",
    "Z_{i,j} \\in \\mathbb{R}^{T \\times F''}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$c_{i,j}^t \\in \\mathcal{R}^{F'}$ <br>\n",
    "$z_{i,j} \\in \\mathcal{R}^{F''}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z_{i,j} = softmax\\left( \\frac{(C_{i,j}W_q) \\cdot (C_{i,j}W_k)^T}{\\sqrt{F''}} + M_i \\right) \\cdot (C_{i,j}W_v)$, where $W_q \\in \\mathbb{R}^{F' \\times F''}$, $W_k \\in \\mathbb{R}^{F' \\times F''} $, $W_v \\in \\mathbb{R}^{F' \\times F''}$ are trainable parameters, $Z_{i,j} \\in \\mathbb{R}^{T \\times F''}$ is the stacked representation of $v_{i,j}$'s sequence, $M_i \\in \\mathbb{R}^{T \\times T}$ is a masked matrix, which is used to avoid the future information leakage and guarantee that the state of each timestamp is only affected by its previous states, $\\begin{equation}\n",
    "  M_i^{t,t'}=\\begin{cases}\n",
    "    0, & \\text{if $t<t'$},\\\\\n",
    "    -\\infty, & \\text{otherwise}.\n",
    "  \\end{cases}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the final representation by the following equation $z_{i,j} = \\left( (Z_{i,j} \\cdot w_{agg})^T \\cdot Z_{i,j}\\right)^T$, where $w_{agg}$ is a trainable parameter to learn the importance of different timestamps adaptively. <br>\n",
    "We finally get $z_{i,j} \\in \\mathbb{R}^{F''}$ as the compact representation for element $v_{i,j}$ that now considers all the possible temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class masked_self_attention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, n_heads=4, attention_aggregate=\"concat\"):\n",
    "        super(masked_self_attention, self).__init__()\n",
    "        # aggregate multi-heads by concatenation or mean\n",
    "        self.attention_aggregate = attention_aggregate\n",
    "\n",
    "        # the dimension of each head is dq // n_heads\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        if attention_aggregate == \"concat\":\n",
    "            self.per_head_dim = self.dq = self.dk = self.dv = output_dim // n_heads\n",
    "        elif attention_aggregate == \"mean\":\n",
    "            self.per_head_dim = self.dq = self.dk = self.dv = output_dim\n",
    "        else:\n",
    "            raise ValueError(f\"wrong value for aggregate {attention_aggregate}\")\n",
    "\n",
    "        # inicialization of the weights as described above in the text\n",
    "        self.Wq = nn.Linear(input_dim, n_heads * self.dq, bias=False)\n",
    "        self.Wk = nn.Linear(input_dim, n_heads * self.dk, bias=False)\n",
    "        self.Wv = nn.Linear(input_dim, n_heads * self.dv, bias=False)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tensor: tensor, shape (nodes_num, T_max, features_num)\n",
    "        Returns:\n",
    "            output: tensor, shape (nodes_num, T_max, output_dim = features_num)\n",
    "        \"\"\"\n",
    "        seq_length = input_tensor.shape[1]\n",
    "        # tensor, shape (nodes_num, T_max, n_heads * dim_per_head)\n",
    "        Q = self.Wq(input_tensor)\n",
    "        K = self.Wk(input_tensor)\n",
    "        V = self.Wv(input_tensor)\n",
    "        # multi_head attention\n",
    "        # Q, tensor, shape (nodes_num, n_heads, T_max, dim_per_head)\n",
    "        Q = Q.reshape(input_tensor.shape[0], input_tensor.shape[1], self.n_heads, self.dq).transpose(1, 2)\n",
    "        # K after transpose, tensor, shape (nodes_num, n_heads, dim_per_head, T_max)\n",
    "        K = K.reshape(input_tensor.shape[0], input_tensor.shape[1], self.n_heads, self.dk).permute(0, 2, 3, 1)\n",
    "        # V, tensor, shape (nodes_num, n_heads, T_max, dim_per_head)\n",
    "        V = V.reshape(input_tensor.shape[0], input_tensor.shape[1], self.n_heads, self.dv).transpose(1, 2)\n",
    "\n",
    "        # scaled attention_score, tensor, shape (nodes_num, n_heads, T_max, T_max)\n",
    "        attention_score = Q.matmul(K) / np.sqrt(self.per_head_dim)\n",
    "\n",
    "        # attention_mask, tensor, shape -> (T_max, T_max)  -inf in the top and right\n",
    "        attention_mask = torch.zeros(seq_length, seq_length).masked_fill(\n",
    "            torch.tril(torch.ones(seq_length, seq_length)) == 0, -np.inf).to(input_tensor.device)\n",
    "        # attention_mask will be broadcast to (nodes_num, n_heads, T_max, T_max)\n",
    "        attention_score = attention_score + attention_mask\n",
    "        # (nodes_num, n_heads, T_max, T_max)\n",
    "        attention_score = torch.softmax(attention_score, dim=-1)\n",
    "\n",
    "        # multi_result, tensor, shape (nodes_num, n_heads, T_max, dim_per_head)\n",
    "        multi_head_result = attention_score.matmul(V)\n",
    "        if self.attention_aggregate == \"concat\":\n",
    "            # multi_result, tensor, shape (nodes_num, T_max, n_heads * dim_per_head = output_dim)\n",
    "            # concat multi-head attention results\n",
    "            output = multi_head_result.transpose(1, 2).reshape(input_tensor.shape[0],\n",
    "                                                               seq_length, self.n_heads * self.per_head_dim)\n",
    "        elif self.attention_aggregate == \"mean\":\n",
    "            # multi_result, tensor, shape (nodes_num, T_max, dim_per_head = output_dim)\n",
    "            # mean multi-head attention results\n",
    "            output = multi_head_result.transpose(1, 2).mean(dim=2)\n",
    "        else:\n",
    "            raise ValueError(f\"wrong value for aggregate {self.attention_aggregate}\")\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregate_nodes_temporal_feature(nn.Module):\n",
    "\n",
    "    def __init__(self, item_embed_dim):\n",
    "        \"\"\"\n",
    "        :param item_embed_dim: the dimension of input features\n",
    "        \"\"\"\n",
    "        super(aggregate_nodes_temporal_feature, self).__init__()\n",
    "\n",
    "        self.Wq = nn.Linear(item_embed_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, graph, lengths, nodes_output):\n",
    "        \"\"\"\n",
    "        :param graph: batched graphs, with the total number of nodes is `node_num`,\n",
    "                        including `batch_size` disconnected subgraphs\n",
    "        :param lengths: tensor, (batch_size, )\n",
    "        :param nodes_output: the output of self-attention model in time dimension, (n_1+n_2+..., T_max, F)\n",
    "        :return: aggregated_features, (n_1+n_2+..., F)\n",
    "        \"\"\"\n",
    "        nums_nodes, id = graph.batch_num_nodes(), 0\n",
    "        aggregated_features = []\n",
    "        for num_nodes, length in zip(nums_nodes, lengths):\n",
    "            # get each user's length, tensor, shape, (user_nodes, user_length, item_embed_dim)\n",
    "            output_node_features = nodes_output[id:id + num_nodes, :length, :]\n",
    "            # weights for each timestamp, tensor, shape, (user_nodes, 1, user_length)\n",
    "            # (user_nodes, user_length, 1) transpose to -> (user_nodes, 1, user_length)\n",
    "            weights = self.Wq(output_node_features).transpose(1, 2)\n",
    "            # (user_nodes, 1, user_length) matmul (user_nodes, user_length, item_embed_dim)\n",
    "            # -> (user_nodes, 1, item_embed_dim) squeeze to (user_nodes, item_embed_dim)\n",
    "            # aggregated_feature, tensor, shape, (user_nodes, item_embed_dim)\n",
    "            aggregated_feature = weights.matmul(output_node_features).squeeze(dim=1)\n",
    "            aggregated_features.append(aggregated_feature)\n",
    "            id += num_nodes\n",
    "        # (n_1+n_2+..., item_embed_dim)\n",
    "        aggregated_features = torch.cat(aggregated_features, dim=0)\n",
    "        return aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

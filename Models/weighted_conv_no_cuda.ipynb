{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORAL SET PREDICTION USING GRAPH BASED APPROACHES."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the accompanying notebook to the Medium Blog entitled [\"'Don't forget the milk again!': Predicting temporal shopping sets using Graph Neural Networks\"](https://medium.com/@wwwidonja/dont-forget-the-milk-again-adc8924fdbe1). It was prepared as part of the Stanford CS224W course project @UL FRI; 2021/22 by Sara Bizjak, Maruša Oražem and Vid Stropnik. While this notebook is meant to be self-sufficient, it will be best experienced by concurrently reading the accompanying blog, linked above. Here, a more robust and theorethical overview of the model and problem at hand will be given, while the blog contextualizes the intent of the model more thoroughly and also gives a good introduction into the theory used here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_items = [i for i in list(pd.read_csv(os.path.join('..\\\\data\\\\', 'transaction_data_smaller.csv')).PRODUCT_ID.unique())]\n",
    "num_all_unique_items = len(all_unique_items)\n",
    "reverse_uid = {str(item_code) : idx for idx, item_code in enumerate(all_unique_items)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to construct a convolutions on dynamic graphs. \n",
    "Input for this module is a sequence of dynamic graphs $\\mathbb{G}_i = \\{\\mathcal{G}_i^1,...\\mathcal{G}_i^T\\}$, where graph $\\mathcal{G}_i^t \\in \\mathbb{G}_i$ has a sequene of elements represented as $\\{e_{i,j}^t \\in \\mathbb{R}^F, \\forall v_{i,j} \\in \\mathcal{V}_i\\}$. (F is the dimention of element representation equal to `in_features` and *i* is the considered household)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each graph $\\mathcal{G}_i$ the output of this modelue is a new sequence representation, which we will denote as  $\\{c_{i,j}^t \\in \\mathbb{R}^{F'}, \\forall v_{i,j} \\in \\mathcal{V}_i\\}$. (F' is the new dimension equal to `out_features`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the parameter scale and also make our method flexible to deal with sequences with variable lengths, a parameter sharing strategy is adopted. The weighted convolutions are implemented by propagating information of elements in each dynamic graphs as follows. For graph $\\mathcal{G}_i$\n",
    "$$c_{i,j}^{t,l+1} = \\sigma\\left( b^l + \\sum_{k \\in N_{i,j}^t \\cup \\{j\\}}   A_i^t[j,k] \\cdot \\left( W^t c_{i,k}^{t,l} \\right) \\right),$$ where $A_i^t[j,k]$ represents the item in j-th row and k-th column of matrix $A_i^t$, which is the edge weight of $v_{i,j}$ and $v_{i,k}$ in graph $\\mathcal{G}_i^t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to override the `nn.Module` for constructing our convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional layer**\n",
    "For the convolutions, we're going to use the `GCNConv` layer from the PyG library. The convolutions are realized as follows:\n",
    "\n",
    "$$\\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "\\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta}$$, where $\\mathbf{\\hat{A}} = \\mathbf{A + I}$ is the adjacency matrix of a graph with inserted self-loops, and $\\mathbf{\\hat{D}}$ is its diagonal degree matrix.\n",
    "\n",
    "PyG makes the use of convolutions simple by simpy asking us to input the node feature tensor of shape `[num_of_nodes, num_of_features]` and its Sparse transposed adjecency matrix `adj_t`, which takes into account the weights in our graphs.\n",
    "\n",
    "Here are some other terms needed to understand the following code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.ModuleList()` - Holds submodules in a list. <br>\n",
    "`nn.ReLU()` - Applies the rectified linear unit function element-wise: ReLU(x) = max(0,x) <br>\n",
    "`nn.BatchNorm1d` - Applies Batch Normalization over a 2D or 3D input. $y=\\frac{x-E[x]}{\\sqrt{var[x]+\\epsilon}} \\cdot \\gamma + \\beta$, The mean and standard-deviation are calculated per-dimension over the mini-batches and \\gammaγ and \\betaβ are learnable parameter vectors of size C (where C is the input size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weighted_GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_sizes, out_features):\n",
    "        '''\n",
    "        :param in_features: int, number of input features\n",
    "        :param hidden_sizes: List[int], list of integers of hidden sizes\n",
    "        :param out_features: int, number of output features\n",
    "        '''\n",
    "        super(weighted_GCN, self).__init__()\n",
    "        # we are going to use 3 layers, first graph conv we wrote before, ReLu function and normalization\n",
    "        gcns, relus, bns = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()\n",
    "        \n",
    "        # layers for hidden_size\n",
    "        input_size = in_features\n",
    "        for hidden_size in hidden_sizes:\n",
    "            # go through all the layers and call all three functions\n",
    "            gcns.append(GCNConv(in_channels=input_size, \n",
    "                            out_channels=hidden_size,\n",
    "                            improved=False,\n",
    "                            cached=False,\n",
    "                            add_self_loops=False,\n",
    "                            normalize=False,\n",
    "                            bias=False)) \n",
    "            relus.append(nn.ReLU())\n",
    "            bns.append(nn.BatchNorm1d(hidden_size))\n",
    "            input_size = hidden_size # next layer start size will be output from one layer before\n",
    "        \n",
    "        # output layer\n",
    "        gcns.append(GCNConv(in_channels=hidden_sizes[-1], \n",
    "                            out_channels=out_features,\n",
    "                            improved=False,\n",
    "                            cached=False,\n",
    "                            add_self_loops=False,\n",
    "                            normalize=False,\n",
    "                            bias=False\n",
    "                            )\n",
    "                   )\n",
    "        relus.append(nn.ReLU())\n",
    "        bns.append(nn.BatchNorm1d(out_features))\n",
    "        self.gcns, self.relus, self.bns = gcns, relus, bns\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        \"\"\"\n",
    "        :param graph: dgl.DGLGraph\n",
    "        :param node_features: torch.Tensor shape (n_1+n_2+..., n_features)\n",
    "               edges_weight: torch.Tensor shape (T, n_1^2+n_2^2+...)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        for gcn, relu, bn in zip(self.gcns, self.relus, self.bns):\n",
    "            \n",
    "            #run the Convolutional layer\n",
    "            h = gcn(h, adj_t)\n",
    "            #run the batch norm\n",
    "            h = bn(h.transpose(1, -1)).transpose(1, -1)\n",
    "            #run the ReLu\n",
    "            h = relu(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graphs from files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import os.path as osp\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
    "import torch_geometric.transforms as T\n",
    "import torch_sparse\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "f1 = 32  ## F'\n",
    "hidden_dims = [32, 32]\n",
    "\n",
    "shopping_per_hh = {}\n",
    "\n",
    "#This is just a test -- we're only constructing the graphs for houshold id 22 as a proof of concept!\n",
    "print('Creating graphs from files')\n",
    "if not path.exists(path.join(\"..\\\\data\\\\pickles\", f\"shopping_per_hh_F1_{f1}_hid_{hidden_dims}.pkl.gz\")):\n",
    "    for filename in tqdm(os.listdir(\"../data/Test-Graphs/content/Graphs/\")):\n",
    "        splits = filename.split('_')\n",
    "        hh_id = splits[0]\n",
    "        if hh_id not in shopping_per_hh: shopping_per_hh[hh_id] = []\n",
    "\n",
    "\n",
    "        ## we construct a NX graph and cast it to pytorch.data.Data\n",
    "        G = nx.Graph(nx.read_pajek(os.path.join(\"../data/Test-Graphs/content/Graphs/\",filename)))\n",
    "        data = from_networkx(G)\n",
    "        \n",
    "        articles_in_basket = [i for i in list(G.nodes()) if i not in list(nx.isolates(G))] # vsi izdelki ki so v kosarici\n",
    "        \n",
    "        gt = torch.zeros(num_all_unique_items)\n",
    "        indices_in_E = [reverse_uid[i] for i in articles_in_basket]\n",
    "        gt[indices_in_E] = 1\n",
    "        gt = gt.to_sparse()\n",
    "\n",
    "        ## Then, we override the data.x in data to get the desired format of the dimensions.\n",
    "        ## We're just using a vector of ones here. We can chamge this in the long run to get more expressivness.\n",
    "        x = torch.ones(G.number_of_nodes(), 1)\n",
    "        data.x = x\n",
    "        data.id = {i:code for (i, code) in zip ([i for i in range(G.number_of_nodes())], list(G.nodes()))}\n",
    "        data.y = gt\n",
    "\n",
    "        shopping_per_hh[hh_id].append(data)\n",
    "    \n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"shopping_per_hh_F1_{f1}_hid_{hidden_dims}.pkl.gz\"), \"wb\") as f:\n",
    "        pickle.dump(shopping_per_hh, f)\n",
    "\n",
    "else:\n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"shopping_per_hh_F1_{f1}_hid_{hidden_dims}.pkl.gz\"), \"rb\") as f:\n",
    "        shopping_per_hh = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models and converting them to tensors\n"
     ]
    }
   ],
   "source": [
    "final_tensors = {}\n",
    "print('Running models and converting them to tensors')\n",
    "if not path.exists(path.join(\"..\\\\data\\\\pickles\", f\"final_tensors_F1_{f1}_hid_{hidden_dims}.pkl.gz\")): \n",
    "    for hh in tqdm(list(shopping_per_hh.keys())):\n",
    "        \n",
    "        \"\"\" Check why we need this try/catch block -- if it causes problems, come here and try to fix it.\"\"\"\n",
    "        \n",
    "        try:   \n",
    "            in_dims = shopping_per_hh[hh][0].num_features\n",
    "            model = weighted_GCN(in_dims, \n",
    "                                 hidden_dims, \n",
    "                                 f1)\n",
    "\n",
    "            embeddings_at_t = []\n",
    "            ## iterate over all graphs for a givn household\n",
    "            for i in range(len(shopping_per_hh[hh])):\n",
    "                graph = shopping_per_hh[hh][i]\n",
    "                o = model(graph.x,graph.edge_index)\n",
    "                embeddings_at_t.append(o)\n",
    "\n",
    "            ## initialize a dictionary of lists for each item purchased by this household at a shop\n",
    "            item_embeddings = {j : [] for j in range(len(embeddings_at_t[0]))}\n",
    "            for t in range(len(embeddings_at_t)):\n",
    "                for j in range(len(embeddings_at_t[t])):\n",
    "                    ## and add the embeddings for each item to its corresponding temporal index t in the newly created list\n",
    "                    item_embeddings[j].append(embeddings_at_t[t][j].tolist())\n",
    "\n",
    "            ## convert the final 3D array to a tensor and save it to the dictionary for further use.\n",
    "            final_tensors[hh] = torch.tensor(list(item_embeddings.values()))\n",
    "        except ValueError: continue\n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"final_tensors_F1_{f1}_hid_{hidden_dims}.pkl.gz\"), \"wb\") as f:\n",
    "        pickle.dump(final_tensors, f)\n",
    "else:\n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"final_tensors_F1_{f1}_hid_{hidden_dims}.pkl.gz\"), \"rb\") as f:\n",
    "        final_tensors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class masked_self_attention_origi(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, n_heads=4):\n",
    "        super(masked_self_attention_origi, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.per_head_dim = output_dim // n_heads\n",
    "        # inicialization of the weights as described above in the text\n",
    "        self.Wq = nn.Linear(input_dim, n_heads * self.per_head_dim, bias=False)\n",
    "        self.Wk = nn.Linear(input_dim, n_heads * self.per_head_dim, bias=False)\n",
    "        self.Wv = nn.Linear(input_dim, n_heads * self.per_head_dim, bias=False)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tensor: tensor, shape (nodes_num, T_max, features_num)\n",
    "        Returns:\n",
    "            output: tensor, shape (nodes_num, T_max, output_dim = features_num)\n",
    "        \"\"\"\n",
    "        \n",
    "        seq_length = input_tensor.shape[1]\n",
    "        # tensor, shape (nodes_num, T_max, n_heads * dim_per_head)\n",
    "        Q = self.Wq(input_tensor)\n",
    "        K = self.Wk(input_tensor)\n",
    "        V = self.Wv(input_tensor)\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Figure out these transposes/reshapes/permutes (and explain/make them prettier if possible)\n",
    "        \"\"\"\n",
    "        \n",
    "        # multi_head attention\n",
    "        # Q, tensor, shape (nodes_num, n_heads, T_max, dim_per_head)\n",
    "        Q = Q.reshape(input_tensor.shape[0], input_tensor.shape[1], self.n_heads, self.per_head_dim).transpose(1, 2)\n",
    "        # K after transpose, tensor, shape (nodes_num, n_heads, dim_per_head, T_max)\n",
    "        K = K.reshape(input_tensor.shape[0], input_tensor.shape[1], self.n_heads, self.per_head_dim).permute(0, 2, 3, 1)\n",
    "        # V, tensor, shape (nodes_num, n_heads, T_max, dim_per_head)\n",
    "        V = V.reshape(input_tensor.shape[0], input_tensor.shape[1], self.n_heads, self.per_head_dim).transpose(1, 2)\n",
    "\n",
    "        # scaled attention_score, tensor, shape (nodes_num, n_heads, T_max, T_max)\n",
    "        attention_score = Q.matmul(K) / np.sqrt(self.per_head_dim)\n",
    "\n",
    "        # attention_mask, tensor, shape -> (T_max, T_max)  -inf in the top and right\n",
    "        attention_mask = torch.zeros(seq_length, seq_length).masked_fill(\n",
    "            torch.tril(torch.ones(seq_length, seq_length)) == 0, -np.inf)\n",
    "\n",
    "        \n",
    "        \n",
    "        # attention_mask will be broadcast to (nodes_num, n_heads, T_max, T_max)\n",
    "        attention_score = attention_score + attention_mask\n",
    "        \n",
    "        \n",
    "        # (nodes_num, n_heads, T_max, T_max)\n",
    "        attention_score = torch.softmax(attention_score, dim=-1)\n",
    "\n",
    "        # multi_result, tensor, shape (nodes_num, n_heads, T_max, dim_per_head)\n",
    "        multi_head_result = attention_score.matmul(V)\n",
    "        # multi_result, tensor, shape (nodes_num, T_max, n_heads * dim_per_head = output_dim)\n",
    "        # concat multi-head attention results\n",
    "        output = multi_head_result.transpose(1, 2).reshape(input_tensor.shape[0],\n",
    "                                                           seq_length, self.n_heads * self.per_head_dim)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregate_nodes_temporal_feature_origi(nn.Module):\n",
    "\n",
    "    def __init__(self, item_embed_dim):\n",
    "        \n",
    "        \"\"\"\n",
    "        :param item_embed_dim: the dimension of input features\n",
    "        \"\"\"\n",
    "        \n",
    "        super(aggregate_nodes_temporal_feature_origi, self).__init__()\n",
    "\n",
    "        self.Wq = nn.Linear(item_embed_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, Z):\n",
    "        ### Equation 4 in the paper\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: CHECK IF THESE TRANSPOSES ARE OK\n",
    "        \n",
    "        \"\"\"\n",
    "        output = self.Wq(Z).transpose(1,2).matmul(Z).transpose(1,2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the self attention masked tensors for every household and pickle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = 32 ## F''\n",
    "\"\"\"\n",
    "###TODO - check if masked_self_attention_origi is working OK, since it only returns a tensor of dim=f2 if f2%4==0\n",
    "PS: It's not. Must fix this!!!!!\n",
    "\"\"\"\n",
    "\n",
    "attention_tensors = {}\n",
    "if not path.exists(path.join(\"..\\\\data\\\\pickles\", f\"attention_tensors_F1_{f1}_F2_{f2}.pkl.gz\")): \n",
    "    for hh in tqdm(final_tensors.keys()):\n",
    "        tens = final_tensors[hh]\n",
    "        tens = tens\n",
    "        model1 = masked_self_attention_origi(input_dim=f1, output_dim=f2)\n",
    "        model1 = model1\n",
    "        o = model1(tens)\n",
    "        model_2 = aggregate_nodes_temporal_feature_origi(item_embed_dim=f2)\n",
    "        o2 = model_2(o)\n",
    "        attention_tensors[hh] = o2[:,:,0]\n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"attention_tensors_F1_{f1}_F2_{f2}.pkl.gz\"), \"wb\") as f:\n",
    "        pickle.dump(attention_tensors, f)\n",
    "else:\n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"attention_tensors_F1_{f1}_F2_{f2}.pkl.gz\"), \"rb\") as f:\n",
    "        attention_tensors = pickle.load(f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Information Fusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class global_gated_update(nn.Module):\n",
    "    ### num_all_unique_items, f0\n",
    "    def __init__(self, items_total, f0, item_dict):\n",
    "        super(global_gated_update, self).__init__()\n",
    "        \n",
    "        self.num_items_total = items_total\n",
    "        self.embedding_dim = f0\n",
    "        self.E = torch.randn((self.num_items_total, self.embedding_dim))\n",
    "        self.gamma = nn.Parameter(torch.rand(self.num_items_total, 1), requires_grad=True)\n",
    "        self.item_dict = {int(i):item_dict[i] for i in item_dict}\n",
    "        \n",
    "    def forward(self, ids, Z, f2):\n",
    "        num_nodes = len(ids)\n",
    "        beta = torch.zeros(self.num_items_total, 1)\n",
    "        ### masking\n",
    "        nodes_in_graph = ids\n",
    "        rows_in_E = [self.item_dict[code.item()] for code in nodes_in_graph]\n",
    "\n",
    "        beta[rows_in_E] = 1\n",
    "        ### update\n",
    "        E_clone = self.E.clone()\n",
    "        ei_update = (1 - beta * self.gamma) * E_clone\n",
    "        #embed[output_nodes, :] = embed[output_nodes, :] + self.gamma[output_nodes] * output_node_features\n",
    "        #print(self.gamma[rows_in_E] * Z)\n",
    "        ei_update[rows_in_E, :] = ei_update[rows_in_E, :] + self.gamma[rows_in_E] * Z        \n",
    "        return ei_update       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This might not work if the initial graphs don't have identical orderings (.ids) \n",
    "> <font color=\"red\">Yes it does, everything is OK :)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = f2\n",
    "model_fuse = global_gated_update(num_all_unique_items, f0, {i : reverse_uid[i] for i in reverse_uid.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1590 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23084/2651683240.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0mZ\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mattention_tensors\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mhh\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0mids\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshopping_per_hh\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mhh\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m         \u001B[0mE_update\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_fuse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mZ\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m         \u001B[0mE_updates\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mhh\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mE_update\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"..\\\\data\\\\pickles\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf\"E_updates_F1_{f1}_F2_{f2}.pkl.gz\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"wb\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\MLG-Project\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23084/952157358.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, ids, Z, f2)\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[1;31m### masking\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mnodes_in_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mids\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[0mrows_in_E\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mcode\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnodes_in_graph\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mbeta\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrows_in_E\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23084/952157358.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[1;31m### masking\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mnodes_in_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mids\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m         \u001B[0mrows_in_E\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mcode\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnodes_in_graph\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[0mbeta\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrows_in_E\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "E_updates = {}\n",
    "if not path.exists(path.join(\"..\\\\data\\\\pickles\", f\"E_updates_F1_{f1}_F2_{f2}.pkl.gz\")): \n",
    "    for hh in tqdm(attention_tensors.keys()):\n",
    "        Z = attention_tensors[hh]\n",
    "        ids = list(shopping_per_hh[hh][0].id.values())\n",
    "        E_update = model_fuse(ids, Z, f2)\n",
    "        E_updates[hh] = E_update\n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"E_updates_F1_{f1}_F2_{f2}.pkl.gz\"), \"wb\") as f:\n",
    "            pickle.dump(E_updates, f)\n",
    "else:\n",
    "    with open(path.join(\"..\\\\data\\\\pickles\", f\"E_updates_F1_{f1}_F2_{f2}.pkl.gz\"), \"rb\") as f:\n",
    "        E_updates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temporal_set_prediction(nn.Module):\n",
    "    def __init__(self, items_total, item_embedding_dim, reverse_uid):\n",
    "        \"\"\"\n",
    "        :param items_total: int\n",
    "        :param item_embedding_dim: int\n",
    "        :param n_heads: int\n",
    "        :param attention_aggregate: sre\n",
    "        \"\"\"\n",
    "        super(temporal_set_prediction, self).__init__()\n",
    "\n",
    "        ### To je njegov f0\n",
    "        self.item_embedding_dim = item_embedding_dim\n",
    "        \n",
    "        self.reverse_uid = reverse_uid\n",
    "        ## to je njegov num_all_unique_items\n",
    "        self.items_total = items_total\n",
    "        \n",
    "        \n",
    "        self.our_gcn = weighted_GCN(1, [self.item_embedding_dim, self.item_embedding_dim], self.item_embedding_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.stacked_gcn = stacked_weighted_GCN_blocks([weighted_GCN(item_embedding_dim,\n",
    "                                                                     [item_embedding_dim],\n",
    "                                                                     item_embedding_dim)])\n",
    "        \"\"\"\n",
    "\n",
    "        self.masked_self_attention = masked_self_attention_origi(input_dim=self.item_embedding_dim,\n",
    "                                                           output_dim=self.item_embedding_dim)\n",
    "\n",
    "        self.aggregate_nodes_temporal_feature = aggregate_nodes_temporal_feature_origi(self.item_embedding_dim)\n",
    "\n",
    "\n",
    "        \n",
    "        #\n",
    "        #(num_all_unique_items, f0, reverse_uid\n",
    "        #\n",
    "        self.global_gated_update = global_gated_update(items_total=self.items_total,\n",
    "                                                       f0=self.item_embedding_dim,\n",
    "                                                       item_dict=self.reverse_uid)\n",
    "\n",
    "        self.fc_output = nn.Sequential(nn.Linear(self.item_embedding_dim, 1, bias=True),\n",
    "                                       nn.Sigmoid())\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, graph_list_for_hh, hh_ids):\n",
    "        embeddings_at_t = []\n",
    "        for graph in graph_list_for_hh:\n",
    "            o = self.our_gcn(graph.x,graph.edge_index)\n",
    "            embeddings_at_t.append(o)\n",
    "        item_embeddings = {j : [] for j in range(len(embeddings_at_t[0]))}\n",
    "        for t in range(len(embeddings_at_t)):\n",
    "            for j in range(len(embeddings_at_t[t])):\n",
    "                ## and add the embeddings for each item to its corresponding temporal index t in the newly created list\n",
    "                item_embeddings[j].append(embeddings_at_t[t][j].tolist())\n",
    "\n",
    "        ## convert the final 3D array to a tensor and save it to the dictionary for further use.\n",
    "        h = torch.tensor(list(item_embeddings.values()))\n",
    "\n",
    "        h = self.masked_self_attention(h)\n",
    "        h = self.aggregate_nodes_temporal_feature(h)\n",
    "        h = h[:,:,0]\n",
    "        #ids = torch.tensor([i[0] for i in list(graph_list_for_hh[0].id.values())])\n",
    "        h = self.global_gated_update(hh_ids, h, self.item_embedding_dim)\n",
    "        out = self.fc_output(h).squeeze(dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, ids, train_list, test_data, optimizer, loss_fn):\n",
    "    # TODO: Implement a function that trains the model by \n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    ## 2. Feed the data into the model\n",
    "    out = model(train_list, ids)\n",
    "    ## 3., 4. Slice the model output and label by train_idx & feed them to loss\n",
    "    \n",
    "    ## this was used with a train/test split\n",
    "    #loss = loss_fn(out[train_idx], data.y[train_idx][:,0])\n",
    "    #print(test_data)\n",
    "    loss = loss_fn(out, test_data.y.to_dense())\n",
    "    #########################################\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def evaluate(model, loader, loss_fn, evaluator, typ='Validation'):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch in tqdm(loader, desc=f'Evaluation on {typ} set'):\n",
    "        with torch.no_grad():\n",
    "            train_list = batch[:-1]\n",
    "            ids = torch.tensor([int(i[0]) for i in list(train_list[0].id.values())])\n",
    "            pred = model(train_list, ids)\n",
    "        y_true.append(list(batch[-1].y.to_dense()))\n",
    "        y_pred.append(list(pred))\n",
    "\n",
    "    y_true = torch.tensor(y_true).type(torch.LongTensor)\n",
    "    y_pred = torch.tensor(y_pred)\n",
    "    print()\n",
    "    \n",
    "    return {'Recall@K' : evaluator(y_pred, y_true)}\n",
    "\"\"\"\n",
    "def MakeEvaluatorRatK(K):\n",
    "\n",
    "    macro_K = K\n",
    "    def RecallAtK(pred, truth):\n",
    "        p_idx = torch.argsort(pred, descending=True)[:macro_K]\n",
    "        t_idx = truth.nonzero()\n",
    "        num_of_elements = sum(el in p_idx for el in t_idx)\n",
    "        RatK = num_of_elements / len(t_idx)\n",
    "        return RatK\n",
    "\n",
    "    return RecallAtK\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate2(model, ids, train_list, test_data, evaluator):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(train_list, ids)\n",
    "\n",
    "    truth = test_data.y.to_dense()\n",
    "    RatK = evaluator(pred, truth)\n",
    "\n",
    "    return RatK\n",
    "\n",
    "def eval_loss(model, ids, train_list, test_data, loss_fn):\n",
    "    model.eval()\n",
    "    out = model(train_list, ids)\n",
    "    loss = loss_fn(out, test_data.y.to_dense())\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'torch.LongTensor'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics import Recall\n",
    "\n",
    "ev = Recall(mdmc_average = 'global', average='samples', top_k=2)\n",
    "yt = torch.tensor([[1, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0]])\n",
    "yp = torch.tensor([[0.2, 0.3, 0.4, 0.1], [1, 0.2, 0, 0], [0.8, 1, 0.2, 0]])\n",
    "yt.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfor epoch in range(1, 1 + epoch_num):\\n    loss = train(model_solo, shopping_per_hh[\"1000\"][:-1], shopping_per_hh[\"1000\"][-1], optimizer_solo, loss_fn)\\n    if epoch%5 == 0:\\n        print(f\\'epoch : {epoch}/{epoch_num}, loss: \\', loss)\\n'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_solo = temporal_set_prediction(num_all_unique_items, f0, reverse_uid)\n",
    "#model.reset_parameters()\n",
    "optimizer_solo = torch.optim.Adam(model_solo.parameters(), lr=0.005, weight_decay=1e-5)\n",
    "## todo\n",
    "loss_fn = nn.BCELoss()\n",
    "epoch_num = 30\n",
    "\"\"\"\n",
    "for epoch in range(1, 1 + epoch_num):\n",
    "    loss = train(model_solo, shopping_per_hh[\"1000\"][:-1], shopping_per_hh[\"1000\"][-1], optimizer_solo, loss_fn)\n",
    "    if epoch%5 == 0:\n",
    "        print(f'epoch : {epoch}/{epoch_num}, loss: ', loss)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS IS THE MAIN CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Households: 100%|██████████| 537/537 [01:52<00:00,  4.76it/s]\n",
      "Calculating Validation R@K: 100%|██████████| 95/95 [00:06<00:00, 13.77it/s]\n",
      "Calculating Test R@K: 100%|██████████| 159/159 [00:09<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Train: 1188.5875,   Valid: 26.33Test: 43.31  num_skipped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Households: 100%|██████████| 537/537 [01:49<00:00,  4.90it/s]\n",
      "Calculating Validation R@K: 100%|██████████| 95/95 [00:06<00:00, 13.98it/s]\n",
      "Calculating Test R@K: 100%|██████████| 159/159 [00:09<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train: 477.9441,   Valid: 15.41Test: 24.37  num_skipped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Households: 100%|██████████| 537/537 [01:49<00:00,  4.90it/s]\n",
      "Calculating Validation R@K: 100%|██████████| 95/95 [00:06<00:00, 13.72it/s]\n",
      "Calculating Test R@K: 100%|██████████| 159/159 [00:09<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train: 203.7012,   Valid: 5.73Test: 9.08  num_skipped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Households: 100%|██████████| 537/537 [01:53<00:00,  4.75it/s]\n",
      "Calculating Validation R@K: 100%|██████████| 95/95 [00:07<00:00, 12.79it/s]\n",
      "Calculating Test R@K: 100%|██████████| 159/159 [00:10<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train: 90.2458,   Valid: 2.13Test: 3.50  num_skipped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Households: 100%|██████████| 537/537 [01:58<00:00,  4.52it/s]\n",
      "Calculating Validation R@K: 100%|██████████| 95/95 [00:07<00:00, 12.90it/s]\n",
      "Calculating Test R@K: 100%|██████████| 159/159 [00:10<00:00, 15.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train: 42.2776,   Valid: 1.07Test: 1.71  num_skipped: 0\n",
      "Early Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "import copy\n",
    "from torchmetrics import Recall\n",
    "import statistics as st\n",
    "f0 = 32\n",
    "\n",
    "\n",
    "model = temporal_set_prediction(num_all_unique_items, f0, reverse_uid)\n",
    "\n",
    "## make the dictionary into a list that we'll be train-test splitting over\n",
    "list_of_dats = [shopping_per_hh[hh] for hh in shopping_per_hh]\n",
    "\n",
    "### filter the list so that we only have households with at least 5 observations\n",
    "at_least_5 = [i for i in list_of_dats if len(i)>=5]\n",
    "\n",
    "## get the (joint) training data and the test data.\n",
    "training_data, test_idx = train_test_split(\n",
    "    at_least_5, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "## Put the test data in its data loader.\n",
    "test_loader = DataLoader(test_idx)\n",
    "\n",
    "### initialize the loss, evaluators, optimizer and rolling window splitter\n",
    "### that we're gonna us during training.\n",
    "loss_fn = nn.BCELoss()\n",
    "KfortopK = 10\n",
    "#evaluator = Recall(mdmc_average = 'global', average='samples', top_k=KfortopK)\n",
    "\n",
    "#evaluator2 = Recall(mdmc_average = 'global', average='samples', top_k=KfortopK)\n",
    "rolling_window_splitter = TimeSeriesSplit(test_size=1, gap=0, n_splits = 4)\n",
    "\n",
    "\n",
    "evaluator3 = MakeEvaluatorRatK(KfortopK)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "## specify the number of epochs to train for\n",
    "n_epochs = 50\n",
    "\n",
    "best_model = None\n",
    "best_valid_loss= 0\n",
    "best_valid_epoch = 0\n",
    "\n",
    "###initialize the model\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    num_skipped = 0\n",
    "    ## On each iteration, we change which data we use for validation.\n",
    "    ## Then, wee put them into loaders\n",
    "    train_idx, valid_idx= train_test_split(\n",
    "        training_data, test_size=0.15, random_state=200, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tl = DataLoader(train_idx)\n",
    "    vl = DataLoader(valid_idx)\n",
    "    loss = 0\n",
    "\n",
    "\n",
    "    for batch in tqdm(tl, desc='Training Households'):\n",
    "        # we get 4 splits from our household (we learn from each household multiple times).\n",
    "        ids = torch.tensor([int(i[0]) for i in list(batch[-1].id.values())])\n",
    "        loss += train(model, ids, batch[:-1], batch[-1], optimizer, loss_fn)\n",
    "        for learn_from, target_in_list in rolling_window_splitter.split(batch):\n",
    "\n",
    "                target = batch[target_in_list[0]]\n",
    "                lrnd = [batch[i] for i in learn_from]\n",
    "                loss += train(model, ids, lrnd, target, optimizer, loss_fn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #valid_results = evaluate(model, vl, loss_fn, evaluator)\n",
    "    #test_results = evaluate(model, test_loader, loss_fn, evaluator, typ='Testing')\n",
    "\n",
    "    valid_loss = 0\n",
    "    test_loss = 0\n",
    "    for batch in tqdm(vl, desc='Calculating Validation R@K'):\n",
    "        # we get 4 splits from our household (we learn from each household multiple times).\n",
    "        #ids = torch.tensor([int(i[0]) for i in list(batch[-1].id.values())])\n",
    "        #valid_results.append(evaluate2(model, ids, batch[:-1], batch[-1], evaluator3))\n",
    "        ids = torch.tensor([int(i[0]) for i in list(batch[-1].id.values())])\n",
    "        valid_loss += eval_loss(model, ids, batch[:-1], batch[-1], loss_fn)\n",
    "\n",
    "\n",
    "\n",
    "    for batch in tqdm(test_loader, desc='Calculating Test R@K'):        # we get 4 splits from our household (we learn from each household multiple times).\n",
    "        ids = torch.tensor([int(i[0]) for i in list(batch[-1].id.values())])\n",
    "        test_loss += eval_loss(model, ids, batch[:-1], batch[-1], loss_fn)\n",
    "\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_valid_epoch = epoch\n",
    "\n",
    "    # todo - this loss isn't the actual loss.\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "      f'Train: {loss:.4f},   '\n",
    "      f'Valid: {valid_loss:.2f}'\n",
    "      f'Test: {test_loss:.2f} '\n",
    "          f' num_skipped: {num_skipped}')\n",
    "\n",
    "    if epoch-best_valid_epoch > 3:\n",
    "        print('Early Stopping.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## TODO: This still isn't used.\n",
    "## This class was used before for prepping our representations for the attention based temporal learning modulee. It's not used anywhere at the moment.\n",
    "class stacked_weighted_GCN_blocks(nn.ModuleList):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(stacked_weighted_GCN_blocks, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, *input):\n",
    "        nodes_feature, edge_weights = input\n",
    "        h = nodes_feature\n",
    "        for module in self:\n",
    "            h = module(h, edge_weights)\n",
    "        return h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLG-Project",
   "language": "python",
   "name": "mlg-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}